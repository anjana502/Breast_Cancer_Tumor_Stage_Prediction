{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13950351,"sourceType":"datasetVersion","datasetId":8891773}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# 0. Imports & Config\n# ============================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, classification_report\n\nfrom xgboost import XGBClassifier\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# Folder & filenames — update these to match your setup\nDATA_DIR = \"/kaggle/input/tcga-data/data/processed\"   # folder where aligned files live\n\nRNA_FILE   = \"rnaseq_aligned.csv\"          # rows = samples, columns = genes\nMETH_FILE  = \"methylation_aligned.csv\"  # rows = samples, columns = CpGs\nCLIN_FILE  = \"clinical_aligned.csv\"     # rows = samples, columns incl. stage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:53:49.237436Z","iopub.execute_input":"2025-12-01T20:53:49.237805Z","iopub.status.idle":"2025-12-01T20:53:49.808207Z","shell.execute_reply.started":"2025-12-01T20:53:49.237780Z","shell.execute_reply":"2025-12-01T20:53:49.807066Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================================\n# 1. Load Data\n# ============================================================\nrna   = pd.read_csv(os.path.join(DATA_DIR, RNA_FILE), index_col=0)\nmeth  = pd.read_csv(os.path.join(DATA_DIR, METH_FILE), index_col=0)\nclin  = pd.read_csv(os.path.join(DATA_DIR, CLIN_FILE), index_col=0)\n\nprint(\"RNA shape:        \", rna.shape)\nprint(\"Methylation shape:\", meth.shape)\nprint(\"Clinical shape:   \", clin.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:54:15.518689Z","iopub.execute_input":"2025-12-01T20:54:15.519063Z","iopub.status.idle":"2025-12-01T20:55:05.302078Z","shell.execute_reply.started":"2025-12-01T20:54:15.519038Z","shell.execute_reply":"2025-12-01T20:55:05.301037Z"}},"outputs":[{"name":"stdout","text":"RNA shape:         (1092, 60660)\nMethylation shape: (1092, 14165)\nClinical shape:    (1092, 7)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# ============================================================\n# 2. Build Tumor Stage Labels (Normalized to I / II / III / IV)\n# ============================================================\n\ndef normalize_stage(s):\n    \"\"\"Map messy stage strings to I, II, III, IV; else NaN.\"\"\"\n    if pd.isna(s):\n        return np.nan\n    s = str(s).lower()\n    # Order matters: check 'iv' before 'iii', etc.\n    if \"iv\" in s:\n        return \"IV\"\n    if \"iii\" in s:\n        return \"III\"\n    if \"ii\" in s:\n        return \"II\"\n    if \"i\" in s:\n        return \"I\"\n    return np.nan\n\nif \"stage_filled\" in clin.columns:\n    raw_stage = clin[\"stage_filled\"]\nelif \"stage_best\" in clin.columns:\n    raw_stage = clin[\"stage_best\"]\nelse:\n    raise ValueError(\"No 'stage_filled' or 'stage_best' in clinical_aligned.csv\")\n\nlabels = raw_stage.apply(normalize_stage)\n\nprint(\"Stage distribution BEFORE dropping NaNs:\")\nprint(labels.value_counts(dropna=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:56:17.980724Z","iopub.execute_input":"2025-12-01T20:56:17.981727Z","iopub.status.idle":"2025-12-01T20:56:17.991846Z","shell.execute_reply.started":"2025-12-01T20:56:17.981692Z","shell.execute_reply":"2025-12-01T20:56:17.990787Z"}},"outputs":[{"name":"stdout","text":"Stage distribution BEFORE dropping NaNs:\nstage_best\nII     620\nIII    249\nI      179\nNaN     24\nIV      20\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ============================================================\n# 3. Align Samples Across RNA, Methylation, Labels\n# ============================================================\n\ncommon_samples = set(rna.index) & set(meth.index) & set(labels.index)\ncommon_samples = sorted(common_samples)\n\nrna   = rna.loc[common_samples]\nmeth  = meth.loc[common_samples]\nlabels = labels.loc[common_samples]\n\n# Drop samples with unknown stage after normalization\nmask = labels.notna()\nrna   = rna.loc[mask]\nmeth  = meth.loc[mask]\nlabels = labels.loc[mask]\n\nprint(\"\\nAfter alignment & dropping NaN stages:\")\nprint(\"RNA:\", rna.shape, \"Methylation:\", meth.shape, \"Labels:\", labels.shape)\nprint(labels.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:56:20.479919Z","iopub.execute_input":"2025-12-01T20:56:20.480248Z","iopub.status.idle":"2025-12-01T20:56:20.913829Z","shell.execute_reply.started":"2025-12-01T20:56:20.480225Z","shell.execute_reply":"2025-12-01T20:56:20.912826Z"}},"outputs":[{"name":"stdout","text":"\nAfter alignment & dropping NaN stages:\nRNA: (1068, 60660) Methylation: (1068, 14165) Labels: (1068,)\nstage_best\nII     620\nIII    249\nI      179\nIV      20\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# ============================================================\n# 4. Preprocess: Impute & Normalize BEFORE PCA\n# ============================================================\n\n# --- RNA ---\n# Impute per-feature (gene) median, then standardize across samples\nrna_imputed = rna.copy()\nrna_imputed = rna_imputed.apply(lambda col: col.fillna(col.median()), axis=0)\n\n# --- Methylation ---\nmeth_imputed = meth.copy()\nmeth_imputed = meth_imputed.apply(lambda col: col.fillna(col.median()), axis=0)\n\n\ndef compute_pca_from_samples_df(df, n_components=20):\n    \"\"\"\n    df: samples × features\n    1) Standardize features\n    2) PCA\n    Returns: (samples × n_components)\n    \"\"\"\n    X = df.values  # samples × features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    n_comp = min(n_components, X_scaled.shape[0])  # cannot exceed #samples\n    pca = PCA(n_components=n_comp, random_state=SEED)\n    X_pca = pca.fit_transform(X_scaled)\n\n    print(f\"PCA input {df.shape} -> {X_pca.shape}, \"\n          f\"explained variance={pca.explained_variance_ratio_.sum():.2%}\")\n    return X_pca\n\nprint(\"\\n--- Running PCA ---\")\nrna_pca  = compute_pca_from_samples_df(rna_imputed,  n_components=20)\nmeth_pca = compute_pca_from_samples_df(meth_imputed, n_components=20)\n\n# Multimodal PCA fusion\nmulti_pca = np.concatenate([rna_pca, meth_pca], axis=1)\nprint(\"Multimodal PCA shape:\", multi_pca.shape)\n\n# Ensure no NaNs\nrna_pca   = np.nan_to_num(rna_pca)\nmeth_pca  = np.nan_to_num(meth_pca)\nmulti_pca = np.nan_to_num(multi_pca)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:56:23.181834Z","iopub.execute_input":"2025-12-01T20:56:23.182157Z","iopub.status.idle":"2025-12-01T20:56:40.683388Z","shell.execute_reply.started":"2025-12-01T20:56:23.182135Z","shell.execute_reply":"2025-12-01T20:56:40.682621Z"}},"outputs":[{"name":"stdout","text":"\n--- Running PCA ---\nPCA input (1068, 60660) -> (1068, 20), explained variance=35.69%\nPCA input (1068, 14165) -> (1068, 20), explained variance=51.42%\nMultimodal PCA shape: (1068, 40)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# ============================================================\n# 5. Define a Stable VAE for Multimodal PCA\n# ============================================================\n\nclass VAE(nn.Module):\n    def __init__(self, input_dim: int, latent_dim: int = 4):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n        )\n        self.mu = nn.Linear(64, latent_dim)\n        self.logvar = nn.Linear(64, latent_dim)\n\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, input_dim),\n        )\n\n    def encode(self, x):\n        h = self.encoder(x)\n        mu = self.mu(h)\n        logvar = self.logvar(h)\n        return mu, logvar\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z  = self.reparameterize(mu, logvar)\n        recon = self.decode(z)\n        return recon, mu, logvar, z\n\n\ndef vae_loss(recon_x, x, mu, logvar, beta: float = 1.0):\n    recon_loss = nn.MSELoss()(recon_x, x)\n    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n    return recon_loss + beta * kld","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:57:10.513782Z","iopub.execute_input":"2025-12-01T20:57:10.514612Z","iopub.status.idle":"2025-12-01T20:57:10.523910Z","shell.execute_reply.started":"2025-12-01T20:57:10.514586Z","shell.execute_reply":"2025-12-01T20:57:10.523000Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# ============================================================\n# 6. Train VAE on Normalized Multimodal PCA\n# ============================================================\n\n# Further standardize multi_pca before feeding to VAE\nscaler_vae = StandardScaler()\nmulti_pca_scaled = scaler_vae.fit_transform(multi_pca)\nmulti_pca_scaled = np.nan_to_num(multi_pca_scaled)\n\nX_tensor = torch.tensor(multi_pca_scaled, dtype=torch.float32).to(device)\ndataset = TensorDataset(X_tensor)\nloader  = DataLoader(dataset, batch_size=16, shuffle=True)\n\nvae = VAE(input_dim=multi_pca_scaled.shape[1], latent_dim=4).to(device)\noptimizer = torch.optim.Adam(vae.parameters(), lr=5e-4)\n\nn_epochs = 50\nvae.train()\nfor epoch in range(1, n_epochs + 1):\n    epoch_loss = 0.0\n    for (batch,) in loader:\n        batch = batch.to(device)\n        recon, mu, logvar, z = vae(batch)\n        loss = vae_loss(recon, batch, mu, logvar, beta=1.0)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item() * batch.size(0)\n\n    epoch_loss /= len(dataset)\n    if epoch % 10 == 0 or epoch == 1:\n        print(f\"VAE Epoch {epoch:3d}/{n_epochs}  Loss: {epoch_loss:.4f}\")\n\n# Extract stable latent space (mu)\nvae.eval()\nwith torch.no_grad():\n    mu, logvar = vae.encode(X_tensor)\nlatent = mu.cpu().numpy()\nlatent = np.nan_to_num(latent)\nprint(\"VAE latent shape:\", latent.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:57:15.661067Z","iopub.execute_input":"2025-12-01T20:57:15.661948Z","iopub.status.idle":"2025-12-01T20:57:26.500190Z","shell.execute_reply.started":"2025-12-01T20:57:15.661920Z","shell.execute_reply":"2025-12-01T20:57:26.499202Z"}},"outputs":[{"name":"stdout","text":"VAE Epoch   1/50  Loss: 1.0080\nVAE Epoch  10/50  Loss: 1.0012\nVAE Epoch  20/50  Loss: 1.0008\nVAE Epoch  30/50  Loss: 1.0008\nVAE Epoch  40/50  Loss: 1.0006\nVAE Epoch  50/50  Loss: 1.0004\nVAE latent shape: (1068, 4)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# ============================================================\n# 7. Helper: XGBoost Evaluation Function\n# ============================================================\n\ndef evaluate_xgb(X, labels, name):\n    \"\"\"\n    X: np.array, samples × features\n    labels: pd.Series of normalized stages (\"I\", \"II\", \"III\", \"IV\")\n    \"\"\"\n    mask = labels.notna()\n    X = X[mask]\n    y = labels[mask]\n\n    le = LabelEncoder()\n    y_enc = le.fit_transform(y)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y_enc,\n        test_size=0.2,\n        random_state=SEED,\n        stratify=y_enc\n    )\n\n    clf = XGBClassifier(\n        n_estimators=400,\n        max_depth=4,\n        learning_rate=0.05,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        reg_lambda=2.0,\n        objective=\"multi:softprob\",\n        eval_metric=\"mlogloss\",\n        tree_method=\"hist\",\n        random_state=SEED,\n        use_label_encoder=False\n    )\n\n    clf.fit(X_train, y_train)\n\n    y_pred = clf.predict(X_test)\n\n    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n    print(f\"\\n=== {name} ===\")\n    print(\"Weighted F1:\", round(f1, 4))\n\n    # To avoid mismatch: only report on labels actually in y_test\n    test_classes = np.unique(y_test)\n    print(\n        classification_report(\n            y_test,\n            y_pred,\n            labels=test_classes,\n            target_names=le.inverse_transform(test_classes),\n            zero_division=0\n        )\n    )\n\n    return clf, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:57:26.501970Z","iopub.execute_input":"2025-12-01T20:57:26.502318Z","iopub.status.idle":"2025-12-01T20:57:26.511101Z","shell.execute_reply.started":"2025-12-01T20:57:26.502289Z","shell.execute_reply":"2025-12-01T20:57:26.509835Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# ============================================================\n# 8. Run XGBoost on Different Representations\n# ============================================================\n\nmodels = {}\nscores = {}\n\nmodels[\"XGB_RNA\"],   scores[\"RNA PCA\"]        = evaluate_xgb(rna_pca,   labels, \"RNA PCA (XGB)\")\nmodels[\"XGB_METH\"],  scores[\"Methyl PCA\"]     = evaluate_xgb(meth_pca,  labels, \"Methylation PCA (XGB)\")\nmodels[\"XGB_MULTI\"], scores[\"Multimodal PCA\"] = evaluate_xgb(multi_pca, labels, \"Multimodal PCA (XGB)\")\nmodels[\"XGB_VAE\"],   scores[\"VAE latent\"]     = evaluate_xgb(latent,    labels, \"VAE latent (XGB)\")\n\nprint(\"\\n===== Summary of Weighted F1 Scores (XGBoost) =====\")\nfor k, v in scores.items():\n    print(f\"{k:20s}: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:57:26.512610Z","iopub.execute_input":"2025-12-01T20:57:26.512950Z","iopub.status.idle":"2025-12-01T20:57:32.949815Z","shell.execute_reply.started":"2025-12-01T20:57:26.512925Z","shell.execute_reply":"2025-12-01T20:57:32.948998Z"}},"outputs":[{"name":"stdout","text":"\n=== RNA PCA (XGB) ===\nWeighted F1: 0.4663\n              precision    recall  f1-score   support\n\n           I       0.09      0.03      0.04        36\n          II       0.60      0.84      0.70       124\n         III       0.29      0.18      0.22        50\n          IV       0.00      0.00      0.00         4\n\n    accuracy                           0.53       214\n   macro avg       0.25      0.26      0.24       214\nweighted avg       0.43      0.53      0.47       214\n\n\n=== Methylation PCA (XGB) ===\nWeighted F1: 0.4762\n              precision    recall  f1-score   support\n\n           I       0.29      0.11      0.16        36\n          II       0.59      0.80      0.68       124\n         III       0.32      0.20      0.25        50\n          IV       0.00      0.00      0.00         4\n\n    accuracy                           0.53       214\n   macro avg       0.30      0.28      0.27       214\nweighted avg       0.46      0.53      0.48       214\n\n\n=== Multimodal PCA (XGB) ===\nWeighted F1: 0.4796\n              precision    recall  f1-score   support\n\n           I       0.00      0.00      0.00        36\n          II       0.59      0.84      0.69       124\n         III       0.41      0.28      0.33        50\n          IV       0.00      0.00      0.00         4\n\n    accuracy                           0.55       214\n   macro avg       0.25      0.28      0.26       214\nweighted avg       0.44      0.55      0.48       214\n\n\n=== VAE latent (XGB) ===\nWeighted F1: 0.4721\n              precision    recall  f1-score   support\n\n           I       0.12      0.03      0.05        36\n          II       0.60      0.83      0.70       124\n         III       0.32      0.22      0.26        50\n          IV       0.00      0.00      0.00         4\n\n    accuracy                           0.54       214\n   macro avg       0.26      0.27      0.25       214\nweighted avg       0.44      0.54      0.47       214\n\n\n===== Summary of Weighted F1 Scores (XGBoost) =====\nRNA PCA             : 0.4663\nMethyl PCA          : 0.4762\nMultimodal PCA      : 0.4796\nVAE latent          : 0.4721\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}